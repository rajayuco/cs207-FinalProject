{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# autodiffpy Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Being able to calculate derivatives is crucial for optimization, probabilistic inference, simulations and modeling in the physical sciences, and much more. However, functions used for these sorts of purposes in the real world are often very complex, and it can be quite challenging to calculate the derivatives of these functions in practice. Our automatic differentiation (AD) software computes the derivatives of any function, with respect to any and all of the function's variables, to machine-precision-level accuracy, by breaking the function down into its elementary operations and using the chain rule (see **Background** for more details).\n",
    "\n",
    "In addition to calculating derivatives, our AD software can also perform backpropagation.  Backpropagation is the process of altering a function's parameters until the outputs of the function behave as expected.  For example, given a function that has a set of fixed inputs, a set of weights, and a set of desired outputs, our software can be used to tweak the weights until the output of the function matches the desired output.\n",
    "\n",
    "Our AD software has many applications, including for sensitivity analysis, numerical computation, and machine learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automatic differentiation is possible because any function, no matter how complicated, can be represented as a combination of **elementary operations**, such as addition, multiplication, exponentiation, and trigonometry. In other words,  $f(x)$ can be represented as $g_{n}(g_{n-1}(g_{n-2}(...g_1(x))))$, where $g_i(x)$ is the value of the $i^{th}$ elementary operation at x."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automatic differentiation uses the **chain rule** to calculate a function's derivative. Recall that, using the chain rule, the derivative of function $h\\left(u\\left(t\\right)\\right)$ is $\\dfrac{\\partial h}{\\partial t} = \\dfrac{\\partial h}{\\partial u}\\dfrac{\\partial u}{\\partial t}.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, let's say that we want to compute $f^{\\prime}\\left(\\dfrac{\\pi}{16}\\right)$ of a complicated function $f(x)$, where $f'(x)$ denotes the derivative of $f(x)$:\n",
    "$$f\\left(x\\right) = x - \\exp\\left(-2\\sin^{2}\\left(4x\\right)\\right).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The evaluation trace below shows how the function $f(x)$ is broken down into combinations of elementary operations. The first column indexes each elementary operation, with the first row representing the value of $x$ itself.  The second column shows the form of each elementary operation, while the third column shows the form of the derivative of each elementary operation.  The fourth column lists the numerical value of each elementary operation and its derivative, respectively.\n",
    "\n",
    "| Trace    | Elementary Operation &nbsp;&nbsp;&nbsp;| Derivative &nbsp;&nbsp;&nbsp; | $\\left(f\\left(a\\right), \\space f^{\\prime}\\left(a\\right)\\right)$ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|\n",
    "| :------: | :----------------------:               | :------------------------------: | :------------------------------: |\n",
    "| $x_{1}$  | $\\dfrac{\\pi}{16}$                      | $1$                | $\\left(\\dfrac{\\pi}{16}, 1\\right)$ |\n",
    "| $x_{2}$  | $4x_{1}$                               | $4\\dot{x}_{1}$                 | $\\left(\\dfrac{\\pi}{4}, 4\\right)$ |\n",
    "| $x_{3}$  | $\\sin\\left(x_{2}\\right)$               | $\\cos\\left(x_{2}\\right)\\dot{x}_{2}$            | $\\left(\\dfrac{\\sqrt{2}}{2}, 2\\sqrt{2}\\right)$ |\n",
    "| $x_{4}$  | $x_{3}^{2}$                            | $2x_{3}\\dot{x}_{3}$                   | $\\left(\\dfrac{1}{2}, 4\\right)$ |\n",
    "| $x_{5}$  | $-2x_{4}$                              | $-2\\dot{x}_{4}$ | $\\left(-1, -8\\right)$ |\n",
    "| $x_{6}$  | $\\exp\\left(x_{5}\\right)$               | $\\exp\\left(x_{5}\\right)\\dot{x}_{5}$ | $\\left(\\dfrac{1}{e}, - \\dfrac{8}{e}\\right)$ |\n",
    "| $x_{7}$  | $-x_{6}$                               | $-\\dot{x}_{6}$                  | $\\left(-\\dfrac{1}{e}, \\dfrac{8}{e}\\right)$ |\n",
    "| $x_{8}$  | $x_{1} + x_{7}$                        | $\\dot{x}_{1} + \\dot{x}_{7}$ | $\\left(\\dfrac{\\pi}{16} - \\dfrac{1}{e}, 1 + \\dfrac{8}{e}\\right)$ |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, $\\space f^{\\prime}\\left(\\dfrac{\\pi}{16}\\right) = 1 + \\frac{8}{e} = 3.9430355293715385. $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **computational graph** drawn below visualizes the evaluation trace. Each node with an incoming arrow represents an elementary operation, which is applied to the node at the tail-end of that same arrow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![](fig/graph1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our automatic differentiation package uses this approach to calculate the derivatives of a given function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Use the Package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to Install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have distributed our package on PyPI.  Therefore, users only have to enter `pip install autodiffpy` into a terminal to download our package through PyPI.\n",
    "\n",
    "Another way for users to download our package is from our github page: https://github.com/rajayuco/cs207-FinalProject.  To do so, users can (1) click the previous link, click the green \"Clone or Download\" button on the website, and then download the zip file manually, OR (2) download the package folder by typing the following into a terminal: `git clone https://github.com/rajayuco/cs207-FinalProject.git`.\n",
    "\n",
    "To install external dependencies, users can navigate into the package directory from within a terminal and type `pip install -r requirements.txt`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please see the **Implementation** section below for examples of using the package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Software Organization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Our package is structured as follows:\n",
    "    \n",
    "    -autodiffpy\\\n",
    "         -autodiffpy\\\n",
    "              -__init__.py\n",
    "              -autodiff.py\n",
    "              -autodiff_math.py  \n",
    "         -tests\\\n",
    "              -__init__.py\n",
    "              -autodiff_test.py\n",
    "              -autodiff_math_test.py\n",
    "         -docs\\\n",
    "              -autodiffpy_doc.ipynb\n",
    "         -README.md\n",
    "         -setup.py\n",
    "         -requirements.txt\n",
    "         -LICENSE\n",
    "\n",
    "\n",
    "* Our autodiffpy module is organized as follows:\n",
    "    * autodiff class (autodiff.py)\n",
    "        * Overwrites elementary operations (such as `__add__`, `__pow__`, `__mul__`, `__truediv__`, etc.), allowing the calculation of derivatives using automatic differentiation\n",
    "        * Includes the reverse forms of those elementary operations to support both commutative and non-commutative operations (`__radd__`, `__rpow__`, `__rmul__`, `__rtruediv__`, etc.)  \n",
    "        * jacobian method\n",
    "            * Returns an n-dimensional (nd) array representation of the given autodiff instance's derivatives\n",
    "        * backprop method\n",
    "            * Returns the relative error in the inputs of the autodiff instance\n",
    "    * autodiff_math module (autodiff_math.py)\n",
    "        * Contains methods for performing mathematical operations, such as exp(), sinh(), arccos(), tan(), and logistic(), on autodiff instances "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test suite\n",
    "\n",
    "Our test suite is performed through both TravisCI and Coverall.  We make use of both unit testing and doctests, which together break our modules' methods into pieces, subject each piece to a series of tests, and compare the tests' results to what we have declared the output should be.  These tests allow us to detect, in a compartmentalized manner, when new changes to our code cause potential problems.\n",
    "\n",
    "In particular, TravisCI works in parallel with our developed software, as it takes the code we have written and committed to GitHub and runs the test suite that we have defined. So instead of running all tests by hand before deployment, we have been able to focus almost entirely on implementation, meaning we have spent more time building our package and less time checking for structural integrity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The autodiff Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The autodiff class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The module **autodiff** contains three components meant for the user: the class *autodiff*, the method *jacobian*, and the method *backprop*.\n",
    "\n",
    "The *autodiff* class allows users to generate variables, such as `x` and `y`, and then use those variables to form a function. The class then performs automatic differentiation on that function.  In the process, the class calculates (1) the numerical value of that equation and (2) the numerical value of that functions’ derivatives with respect to all variables encountered within the function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To carry out this process, the user must first initialize each variable of the desired function separately, as a different instance of the *autodiff* class.\n",
    "\n",
    "Each variable (aka, *autodiff* instance) requires the following inputs:\n",
    "\n",
    "* `name` [string, required]: The name that the user would like to use for this variable (i.e., \"x\" or \"y\").  \n",
    "* `val` [number/nd-array of numbers, required]: The numerical value/nd-array of values that the user would like to assign to this variable.\n",
    "* `der` [number/nd-array of numbers, required; default=1]: The value/nd-array of this variable’s derivative(s) with respect to itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Note that our package assumes implicitly that the user will give each variable a name unique from all other variables, and that all variables will be given values for `val` (and `der`, if specified) that are of the same dimension.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The user can then perform mathematical operations on these variables in the form of a function.  Doing so will return a new instance of the *autodiff* class, which will have the following output attributes relevant to the user:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `val` [number/nd-array of numbers]: This returns the computed numerical value of the function.\n",
    "* `der` [dictionary]: This returns a dictionary that contains the values of the function’s derivatives, calculated with respect to every single variable encountered in the function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this returned instance of the *autodiff* class, the user therefore has numerical values/nd-arrays of values for both the function and its derivatives, for all variables encountered within the function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Underneath the ‘hood’ of the code, so to speak, the *autodiff* class contains private dunder methods that the user should *not* attempt to access.  These methods override elementary operations (`__add__`, `__sub__`, `__mul__`, `__neg__`, etc.) and the reverse of those operations (`__radd__`, `__rsub__`, `__rmul__`, etc.).  Each overridden method determines the derivatives of the elementary operation, calculated with respect to each unique variable key name contained in the variables’ attribute dictionary `der`.  Each overridden method then returns a new instance of the *autodiff* class, which contains the updated function value/nd-array of values and derivative values/nd-arrays of values stored in its attributes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example below demonstrates how users can interact with the *autodiff* class in our software:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    ">>> # Import the autodiff class\n",
    ">>> from autodiffpy import autodiff as AD\n",
    ">>> # Create variable instances of the class\n",
    ">>> x = AD.autodiff(name=\"x\", val=[3, 1])\n",
    ">>> y = AD.autodiff(name=\"y\", val=[-4.5, 7])\n",
    ">>> # Define the equation to evaluate\n",
    ">>> f = x**2 + y - x/y\n",
    ">>>\n",
    ">>> # Output the results\n",
    ">>> print(f.val) # Numerical value of equation\n",
    "[ 5.16666667  7.85714286]\n",
    ">>> print(f.der[\"x\"]) # Numerical values of equation’s derivative with respect to \"x\"\n",
    "[ 6.22222222  1.85714286]\n",
    ">>> print(f.der[\"y\"]) # Numerical values of equation’s derivative with respect to \"y\"\n",
    "[ 0.85185185,  0.97959184]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The jacobian method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *jacobian* method within the *autodiff* class allows users to format the derivatives of an instance of the *autodiff* class in `numpy` nd-array form.  Users can specify the variables and the ordering that they would like the nd-array to follow using the input argument `order`.  If `order` is not specified, then the ordering of the returned nd-array will be arbitrary.  *jacobian* returns a dictionary, where the `numpy` nd-array is stored beneath the keyword \"jacobian\", and the ordering is stored beneath the keyword \"order\".\n",
    "\n",
    "The below example, which continues from the previous example, demonstrates the operation of the *jacobian* method:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```python\n",
    ">>> # Print the previously-calculated derivatives in numpy array form (real output won’t have rounded values)\n",
    ">>> f.jacobian() # Dictionary containing formatted nd-array form and ordering\n",
    "{'jacobian': array([[ 6.22222222,  1.85714286],\n",
    "       [ 0.85185185,  0.97959184]]), 'order': ['x', 'y']}\n",
    ">>>\n",
    ">>> # Access the formatted nd-array\n",
    ">>> f.jacobian()[\"jacobian\"] \n",
    "array([[ 6.22222222,  1.85714286],\n",
    "       [ 0.85185185,  0.97959184]])\n",
    ">>>\n",
    ">>> # Access just the derivatives for \"x\"\n",
    ">>> f.jacobian(order=\"x\")[\"jacobian\"] \n",
    "array([[ 6.22222222,  1.85714286]])\n",
    ">>>\n",
    ">>> # Format the derivatives in the order of \"y\", \"x\"\n",
    ">>> f.jacobian(order=[\"y\",\"x\"])[\"jacobian\"] \n",
    "array([[ 0.85185185,  0.97959184],\n",
    "       [ 6.22222222,  1.85714286]])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The backprop method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The backpropagation method allows users to calculate the change in variables necessary to bring a function's *actual* outputs closer to outputs *desired* for that function.  Essentially, this method passes errors backward through a given function, and then it determines a gradient that, if applied to the function's variables, will in turn apply a correction to the function relative to the desired outputs.\n",
    "\n",
    "The below example demonstrates a way to use the *backprop* method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!!!!!!\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The autodiff_math Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "External, elementary mathematical operations, exluding simple arithmetic operations, are included in the *autodiff_math* module. Users are required to import this module to perform these operations on autodiff instances, because `numpy` and other standard math libraries in `python` are not equipped to handle instances of our *autodiff* class.\n",
    "\n",
    "The operations in *autodiff_math* include trigonmetric functions, logarithmic functions, exponential functions, and the logistic function. Each operation within this module returns a new autodiff instance with a properly updated value(s) stored in `val` and an updated dictionary of derivatives stored in `der`.\n",
    "\n",
    "The below example demonstrates how to use our *autodiff_math* module:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Import autodiff\n",
    ">>> from autodiffpy import autodiff as AD\n",
    ">>> from autodiffpy import autodiff_math as adm\n",
    ">>>\n",
    ">>> # Create autodiff instances\n",
    ">>> x = AD.autodiff('x', 100) # Create an autodiff instance\n",
    ">>> y = AD.autodiff('y', 1.5) # Create another autodiff instance\n",
    ">>>\n",
    ">>> # Perform external mathematical operations\n",
    ">>> f1 = adm.log(x, base=10)\n",
    ">>> f2 = adm.sinh(f1*y)\n",
    ">>>\n",
    ">>> # Print the results\n",
    ">>> print(f2.val)\n",
    "[ 10.01787493]\n",
    ">>> print(f2.der)\n",
    "{'x': array([ 0.06558495]), 'y': array([ 20.13532399])}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### External Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our package requires `numpy` (version 1.15.1), which we use to organize the output of our *jacobian* method and for performing inner math functions (such as $e^x$) within our *autodiff_math* module. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work for the Future"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our implementation of backpropagation (our *backprop* method in the *autodiff* class) calculates the changes in variables necessary to bring a function's actual outputs closer to given desired outputs.  Our implementation calculates these changes efficiently and to machine precision.\n",
    "\n",
    "However, we note that for certain optimization and machine learning applications, such as for neural networks, linear algebra through matrix operations (i.e., through dot product) is extremely useful.\n",
    "\n",
    "In its current form, our backpropagation method, as well as our autodiffpy package as a whole, cannot *directly* perform matrix operations.  There are ways to work around this restriction with our package; linear algebra, for example, is merely a combination of linear equations, and our package is completely equipped to handle linear equations.  But as of yet, our package cannot perform matrix operations.  For now, we leave implementing matrix operations into our package for future work.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
