{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autodiffpy import autodiff as ad\n",
    "from autodiffpy import autodiff_math as admath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backpropagation evaluation result: [('w0', 1), ('w1', array([3])), ('x1', array([1])), ('w2', array([2])), ('x2', array([-2]))]\n",
      "auto differentiate function evaluation result: {'w0': 1, 'w1': array([3]), 'w2': array([2]), 'x1': array([1]), 'x2': array([-2])}\n",
      "\n",
      " backpropagation evaluation result: [('w0', array([-0.36787944])), ('w1', array([-1.10363832])), ('x1', array([-0.36787944])), ('w2', array([-0.73575888])), ('x2', array([0.73575888]))]\n",
      "auto differentiate function evaluation result: {'w0': array([-0.36787944]), 'w1': array([-1.10363832]), 'w2': array([-0.73575888]), 'x1': array([-0.36787944]), 'x2': array([0.73575888])}\n",
      "\n",
      " backpropagation evaluation result: [('w0', array([0.19661193])), ('w1', array([0.5898358])), ('x1', array([0.19661193])), ('w2', array([0.39322387])), ('x2', array([-0.39322387]))]\n",
      "auto differentiate function evaluation result: {'w0': array([0.19661193]), 'w1': array([0.5898358]), 'w2': array([0.39322387]), 'x1': array([0.19661193]), 'x2': array([-0.39322387])}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def exp(adobj):\n",
    "    '''Returns autodiff instance of log(x)\n",
    "\n",
    "    INPUTS\n",
    "    ==========\n",
    "    ad: autodiff instance\n",
    "\n",
    "    RETURNS\n",
    "    ==========\n",
    "    anew: autodiff instance with updated values and derivatives\n",
    "\n",
    "    EXAMPLES\n",
    "    ==========\n",
    "    >>> from autodiffpy import autodiff\n",
    "    >>> from autodiffpy import autodiff_math as admath\n",
    "    >>> x = autodiff.autodiff('x', 10)\n",
    "    >>> f1 = admath.exp(x)\n",
    "    >>> f1.val = np.exp(10)\n",
    "    '''\n",
    "    \n",
    "\n",
    "    try:\n",
    "        anew = ad.autodiff(name=adobj.name, val = np.exp(adobj.val), der = adobj.der)\n",
    "        anew.lparent = adobj\n",
    "        for key in adobj.der:\n",
    "            anew.der[key] = adobj.der[key]*anew.val\n",
    "        adobj.back_partial_der = anew.val\n",
    "        return anew\n",
    "    except TypeError:\n",
    "        print(\"Error: input should be autodiff instance only.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x1 = ad.autodiff(name=\"x1\", val=3, der=1)\n",
    "x2 = ad.autodiff(name=\"x2\", val=2, der=1)\n",
    "w0 = ad.autodiff(name=\"w0\", val=2, der=1)\n",
    "w1 = ad.autodiff(name=\"w1\", val=1, der=1)\n",
    "w2 = ad.autodiff(name=\"w2\", val=-2, der=1)\n",
    "\n",
    "f =(w0+w1*x1+w2*x2)\n",
    "print('backpropagation evaluation result:', f.backprop())\n",
    "print('auto differentiate function evaluation result:', f.der)\n",
    "\n",
    "f = exp((-1)*(w0+w1*x1+w2*x2))\n",
    "print('\\n backpropagation evaluation result:', f.backprop())\n",
    "print('auto differentiate function evaluation result:', f.der)\n",
    "\n",
    "f = (1+exp((-1)*(w0+w1*x1+w2*x2)))**(-1)\n",
    "\n",
    "print('\\n backpropagation evaluation result:', f.backprop())\n",
    "print('auto differentiate function evaluation result:', f.der)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " backpropagation evaluation result: [('w0', array([1.43239449])), ('w1', array([0.88550171])), ('x1', array([-0.84559184])), ('w2', array([-0.44275085])), ('x2', array([-0.21139796]))]\n",
      "auto differentiate function evaluation result: {'w0': array([1.14591559]), 'w1': array([0.88550171]), 'w2': array([-0.44275085]), 'x1': array([-0.97640535]), 'x2': array([0.24410134])}\n"
     ]
    }
   ],
   "source": [
    "#implementing self-test including: truediv, arcsin, arctan, arccos, subtraction etc\n",
    "x1 = ad.autodiff(name=\"x1\", val=0.5, der=1)\n",
    "x2 = ad.autodiff(name=\"x2\", val=0.5, der=1)\n",
    "w0 = ad.autodiff(name=\"w0\", val=0.5, der=1)\n",
    "w1 = ad.autodiff(name=\"w1\", val=0.5, der=1)\n",
    "w2 = ad.autodiff(name=\"w2\", val=-0.5, der=1)\n",
    "\n",
    "\n",
    "# f1= admath.arcsin(x1)\n",
    "# print('backpropagation evaluation result:', f1.backprop())\n",
    "# print('auto differentiate function evaluation result:', f1.der)\n",
    "\n",
    "# f1= w1/admath.arcsin(x1)\n",
    "# print('\\n backpropagation evaluation result:', f1.backprop())\n",
    "# print('auto differentiate function evaluation result:', f1.der)\n",
    "\n",
    "# # f2 = admath.arccos(x2)\n",
    "# # print('\\n backpropagation evaluation result:', f2.backprop())\n",
    "# # print('auto differentiate function evaluation result:', f2.der)\n",
    "\n",
    "# f2 = w2/admath.arccos(x2)\n",
    "# print('\\n backpropagation evaluation result:', f2.backprop())\n",
    "# print('auto differentiate function evaluation result:', f2.der)\n",
    "\n",
    "# f3= f1-f2\n",
    "# print('\\n backpropagation evaluation result:', f3.backprop())\n",
    "# print('auto differentiate function evaluation result:', f3.der)\n",
    "\n",
    "# f4 = admath.arctan(w0)\n",
    "# print('\\n backpropagation evaluation result:', f4.backprop())\n",
    "# print('auto differentiate function evaluation result:', f4.der)\n",
    "\n",
    "# f5 = f4*f3\n",
    "# print('\\n backpropagation evaluation result:', f5.backprop())\n",
    "# print('auto differentiate function evaluation result:', f5.der)\n",
    "\n",
    "#or\n",
    "\n",
    "f6 = admath.arctan(w0) * (w1/admath.arcsin(x1) - w2/admath.arccos(x2))\n",
    "print('\\n backpropagation evaluation result:', f6.backprop())\n",
    "print('auto differentiate function evaluation result:', f6.der)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5 0.5]\n"
     ]
    }
   ],
   "source": [
    "x1 = ad.autodiff(name=\"x1\", val=[0.5, 0.5], der=1)\n",
    "#x2 = ad.autodiff(name=\"x2\", val=0.5, der=1)\n",
    "w0 = ad.autodiff(name=\"w0\", val=0.5, der=1)\n",
    "w1 = ad.autodiff(name=\"w1\", val=[0.5, -0.5], der=1)\n",
    "#w2 = ad.autodiff(name=\"w2\", val=-0.5, der=1)\n",
    "print(x1.val)\n",
    "#print(w1*x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " backpropagation evaluation result: [('w0', 1), ('w1', array([-1.90985932, -1.90985932])), ('x1', array([ 1.82378131, -1.82378131]))]\n",
      "auto differentiate function evaluation result: {'w0': array([0.8]), 'w1': array([-1.90985932, -1.90985932]), 'x1': array([ 2.10592126, -2.10592126])}\n"
     ]
    }
   ],
   "source": [
    "f6 = admath.arctan(w0)-(w1/admath.arcsin(x1))- w2/admath.arccos(x2))\n",
    "print('\\n backpropagation evaluation result:', f6.backprop())\n",
    "print('auto differentiate function evaluation result:', f6.der)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(map(lambda x:x**2>1, [0.5, 0.5]))==True\n",
    "f2 =admath.arcsin(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('w0', 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f6.backprop()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# questions:\n",
    "- der should be same with backpropagation when function value are the same, or what condition?\n",
    "- when using autodiff math, there no new autodiff object generated and calculated partial derivation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_backpropagation_arc():\n",
    "    '''function for testing backpropagation'''\n",
    "    x1 = ad.autodiff(name=\"x1\", val=0.5, der=1)\n",
    "    x2 = ad.autodiff(name=\"x2\", val=0.5, der=1)\n",
    "    w0 = ad.autodiff(name=\"w0\", val=0.5, der=1)\n",
    "    w1 = ad.autodiff(name=\"w1\", val=0.5, der=1)\n",
    "    w2 = ad.autodiff(name=\"w2\", val=-0.5, der=1)\n",
    "\n",
    "    f = admath.arctan(w0) * (w1/admath.arcsin(x1) - w2/admath.arccos(x2))\n",
    "    assert abs(f.backprop()[0][2] - 1.4323944878270578) < 1E-10\n",
    "    assert abs(f.backprop()[1][2] - 0.8855017059025995) < 1E-10\n",
    "    assert abs(f.backprop()[2][2] - (-0.8455918416642267)) < 1E-10\n",
    "    assert abs(f.backprop()[3][2] - (-0.44275085295129973)) < 1E-10\n",
    "    assert abs(f.backprop()[4][2] - (-0.21139796041605668)) < 1E-10\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
